## ML-Coursera

Neural Network Week 4 - 

Quiz 1 - 
1. 	
<ol>
  <li>TRUE - 
    <ul>
      <li>Any logical function over binary-valued (0 or 1) inputs x1 and x2 can be (approximately) represented using some neural network.
</li>
      <li>The activation values of the hidden units in a neural network, with the sigmoid activation function applied at every layer, are always in the range (0, 1).	</li>
    </ul>
  </li>
  <li>NAND</li>
  <li>This correctly uses the first row of Î˜(2) and includes the "+1" term of a(2)0</li>
  <li>Remains Same</li>


</ol>


Gradient Descent - 

  <image src="https://github.com/souvik0306/ML-Coursera/blob/main/Linear%20Regression/Gradient%20Descent.gif" width="550" height="450">
